{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "huyler_landing_url = 'https://www.alltrails.com/trail/us/new-jersey/huylers-landing-trail'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'} # This is chrome, you can set whatever browser you like\n",
    "r = requests.get(huyler_landing_url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "\n",
    "db = client.alltrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = db.huyler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7fa7da96cd70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.insert_one({'link': huyler_landing_url ,'html': r.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"styles-module__detailData___kQ-eK\">2.2 mi</span>,\n",
       " <span class=\"styles-module__detailData___kQ-eK\">410 ft</span>,\n",
       " <span class=\"styles-module__detailData___kQ-eK\">Out &amp; back</span>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trail title, description, difficulty, info\n",
    "soup.find_all('h1', class_='xlate-none styles-module__name___1nEtW')\n",
    "soup.find_all('p', id=\"auto-overview\")\n",
    "soup.find_all('span', class_=\"styles-module__diff___22Qtv styles-module__moderate___3w1it styles-module__selected___3fawg\")\n",
    "soup.find_all('span', class_=\"styles-module__detailData___kQ-eK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "written_review = \"\"\n",
    "ratings = []\n",
    "dates = []\n",
    "types = []\n",
    "review_text = []\n",
    "reviewer_links = []\n",
    "\n",
    "for i, review in enumerate(soup.find_all('div', itemprop=\"review\")):\n",
    "\n",
    "    ratings.append(soup.find_all('span', class_=\"MuiRating-root default-module__rating___1k45X MuiRating-sizeLarge MuiRating-readOnly\")[i]['aria-label'])\n",
    "    dates.append(soup.find_all('span', class_=\"styles-module__dateTrailDetails___3qgZC xlate-none\")[i].text.rstrip())\n",
    "    types.append(soup.find_all('span', class_=\"styles-module__tag___2s-oD styles-module__activityTag___3-RdN\")[i].text.rstrip())\n",
    "    \n",
    "    written_review = soup.find_all('div', class_=\"styles-module__container___3etfA\")[i].find('p', itemprop=\"reviewBody\")\n",
    "    if written_review != None:\n",
    "        review_text.append(soup.find_all('div', class_=\"styles-module__container___3etfA\")[i].find('p', itemprop=\"reviewBody\").text.rstrip())\n",
    "        \n",
    "    reviewer_links.append('alltrails.com' + soup.find_all('div', class_=\"styles-module__container___3etfA\")[1].find('a', class_=\"styles-module__link___2i6Za styles-module__recording___3jQX3 xlate-none\")['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in reviews:\n",
    "    reviewer_link = 'alltrails.com' + soup.find_all('div', class_=\"styles-module__container___3etfA\")[1].find('a', class_=\"styles-module__link___2i6Za styles-module__recording___3jQX3 xlate-none\")['href']\n",
    "    soup.find_all('div', class_='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,links in enumerate(link):\n",
    "\n",
    "    # step 1: inspect webpage -- since they have similar structure, I can check out one of the links\n",
    "    # step 2: get the HTML code via requests library\n",
    "    sub_page = requests.get(links)\n",
    "    \n",
    "    #step 3: put HTML into MongoDB \n",
    "    # here I made the key as the link to the page and value the html code\n",
    "    pages.insert_one({'link':links ,'html': sub_page.text})\n",
    "    \n",
    "    # Add time between request to try to prevent this from happening\n",
    "    print('Website number {}   website link: {}'.format(i,links) )\n",
    "    time.sleep(2)   # If you request too much code too quickly you can get banned from scrapping the site!\n",
    "    \n",
    "    # I have added this so that it does not take to long to run \n",
    "    if i > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post lunch steps:\n",
    "    —selenium tutorial\n",
    "    — set scraper for review pages \n",
    "        • save pages to mongo\n",
    "        • get desired info\n",
    "    — "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
