{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "    gather data for three more hikes\n",
    "    loop through data\n",
    "    create dataframes\n",
    "    join df's for 4 and 5 stars\n",
    "    perform z-test\n",
    "\n",
    "Step 2:\n",
    "    perform further statistical tests\n",
    "    gather more hike data?\n",
    "    gather data on individual users and perform further tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting hiking trail links\n",
    "links = ['https://www.alltrails.com/trail/us/new-jersey/long-path-gw-bridge-to-lamont-doherty-earth-observatory']\n",
    "\n",
    "links.append('https://www.alltrails.com' + get <a itemprop=\"url\" ('href') \"/explore/trail/us/new-jersey/long-path-gw-bridge-to-lamont-doherty-earth-observatory?ref=result-card\"\n",
    "    and remove '/explore' —> BINGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.alltrails.com/trail/us/new-jersey/shore-trail-and-long-trail-loop-from-alpine-picnic-area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-5fa952c48795>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-5fa952c48795>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    pages = db.{trail_name} #insert trail_name???\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# instantiating variables to be columns in dataframe\n",
    "written_review = \"\"\n",
    "ratings = []\n",
    "dates = []\n",
    "types = []\n",
    "review_text = []\n",
    "reviewer_links = []\n",
    "\n",
    "# Loop through links to get html, save to mongo, extract relevant data\n",
    "for link in links:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(link)\n",
    "    sleep(3)\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, 10000)\")\n",
    "\n",
    "# find 'show more reviews button'\n",
    "    search = driver.find_element_by_css_selector(\"#reviews > div.styles-module__container___px-t2.xlate-none > button\")\n",
    "    \n",
    "#prevents error being thrown once total trail reviews is reached; \n",
    "    total = driver.find_element_by_css_selector('#reviews > div.styles-module__container___px-t2.xlate-none > div')\n",
    "    total_ = int(total.text.split(' ')[-1])\n",
    "\n",
    "# clicks through to see additional reviews\n",
    "    for _ in range(round(total_/25)):\n",
    "        search.click()\n",
    "        sleep(1)\n",
    "\n",
    "# get page html\n",
    "    html = driver.page_source\n",
    "    time.sleep(2)\n",
    "\n",
    "# add html to mongo\n",
    "    client = MongoClient()\n",
    "    db = client.alltrails\n",
    "    trail_name = ('https://www.alltrails.com/trail/us/new-jersey/long-path-gw-bridge-to-lamont-doherty-earth-observatory'.split('/'))[-1]\n",
    "    pages = db.trailname #insert trail_name???\n",
    "    pages.insert_one({'link': link ,'html': html})\n",
    "\n",
    "# parsing data\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# getting trail title, description, difficulty, info\n",
    "    soup.find('h1', class_='xlate-none styles-module__name___1nEtW').text.rstrip()\n",
    "    soup.find('p', id=\"auto-overview\").text.rstrip()\n",
    "    soup.find('span', class_=\"styles-module__diff___22Qtv styles-module__moderate___3w1it styles-module__selected___3fawg\").text.rstrip()\n",
    "    soup.find('span', class_=\"styles-module__detailData___kQ-eK\").text.rstrip()\n",
    "\n",
    "# getting reviewer data for trail, appending to lists\n",
    "    for i, review in enumerate(soup.find_all('div', itemprop=\"review\")):\n",
    "\n",
    "        ratings.append(soup.find_all('span', class_=\"MuiRating-root default-module__rating___1k45X MuiRating-sizeLarge MuiRating-readOnly\")[i]['aria-label'])\n",
    "        dates.append(soup.find_all('span', class_=\"styles-module__dateTrailDetails___3qgZC xlate-none\")[i].text.rstrip())\n",
    "        types.append(soup.find_all('span', class_=\"styles-module__tag___2s-oD styles-module__activityTag___3-RdN\")[i].text.rstrip())\n",
    "\n",
    "        written_review = soup.find_all('div', class_=\"styles-module__container___3etfA\")[i].find('p', itemprop=\"reviewBody\")\n",
    "\n",
    "        if written_review == None:\n",
    "            review_text.append(None)\n",
    "\n",
    "        else:\n",
    "            review_text.append(soup.find_all('div', class_=\"styles-module__container___3etfA\")[i].find('p', itemprop=\"reviewBody\").text.rstrip())        \n",
    "\n",
    "        reviewer_links.append('alltrails.com' + soup.find_all('div', class_=\"styles-module__container___3etfA\")[1].find('a', class_=\"styles-module__link___2i6Za styles-module__recording___3jQX3 xlate-none\")['href'])\n",
    "    \n",
    "    # for trail in find('ul', class_=\" float-delete-button\").find_all('li', class_=\"styles-module__container___10uYZ\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data into dataframe\n",
    "df = pd.DataFrame({'rating': ratings, 'date':dates, 'desc': types, 'reviews': review_text, 'links': reviewer_links}).sort_values('rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist Approach"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scientific Question: Are 4-star reviewers more likely than 5-star reviewers to leave written reviews?\n",
    "H0:  4 and 5 star reviewers are equally likely to leave written reviews — P(R | 4) = P(R | 5)\n",
    "Ha: 4 and 5 star reviewers leave written reviews at different rates — P(R | 4) != P(R | 5)\n",
    "Test Statistic: 4-Stars: 15/46 and 5-Stars: 9/73\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b31de_row0_col0,#T_b31de_row0_col1,#T_b31de_row1_col0,#T_b31de_row1_col1{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_b31de_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >4 Stars</th>        <th class=\"col_heading level0 col1\" >5 Stars</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b31de_level0_row0\" class=\"row_heading level0 row0\" >Written Reviews</th>\n",
       "                        <td id=\"T_b31de_row0_col0\" class=\"data row0 col0\" >15</td>\n",
       "                        <td id=\"T_b31de_row0_col1\" class=\"data row0 col1\" >9</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b31de_level0_row1\" class=\"row_heading level0 row1\" >Total Reviewers</th>\n",
       "                        <td id=\"T_b31de_row1_col0\" class=\"data row1 col0\" >46</td>\n",
       "                        <td id=\"T_b31de_row1_col1\" class=\"data row1 col1\" >73</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc442d9d510>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five = df[df['rating'] == '5 Stars']['reviews'].count() #num of written reviews left by five-star reviewers\n",
    "four = df[df['rating'] == '4 Stars']['reviews'].count() #num of written reviews left by four-star reviewers\n",
    "num_five = df[df['rating']=='5 Stars']['rating'].count() #num of five-star reviewers\n",
    "num_four = df[df['rating']=='4 Stars']['rating'].count() #num of four-star reviewers\n",
    "\n",
    "table = pd.DataFrame({'Written Reviews': [four, five], 'Total Reviewers': [num_four, num_five]}, index = ['4 Stars', '5 Stars']).T\n",
    "table = table.style.set_properties(**{'text-align': 'center'})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it is obvious that a much higher percentage of 4 star reviewers left written reviews than 5 star reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayseian Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
